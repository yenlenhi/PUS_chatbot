# ğŸ”„ BÆ°á»›c 7: Cáº­p Nháº­t RAG Service

HÆ°á»›ng dáº«n chi tiáº¿t Ä‘á»ƒ cáº­p nháº­t `src/services/rag_service.py` Ä‘á»ƒ sá»­ dá»¥ng PostgreSQL + Hybrid Retrieval.

## ğŸ“‹ Tá»•ng Quan Thay Äá»•i

### CÅ© (SQLite + FAISS)
```python
# Sá»­ dá»¥ng SQLite database
from src.services.database_service import DatabaseService

# Sá»­ dá»¥ng FAISS vector search
from src.services.faiss_service import FAISSService

# Sá»­ dá»¥ng BM25 tá»« file
self.bm25_index = load_bm25_index()
```

### Má»›i (PostgreSQL + Hybrid Retrieval)
```python
# Sá»­ dá»¥ng PostgreSQL database
from src.services.postgres_database_service import PostgresDatabaseService

# Sá»­ dá»¥ng Hybrid Retrieval (dense + sparse)
from src.services.hybrid_retrieval_service import HybridRetrievalService

# TÃ­ch há»£p Ingestion Service
from src.services.ingestion_service import IngestionService
```

## ğŸ”§ CÃ¡c Thay Äá»•i Cáº§n LÃ m

### 1. Import Statements
**ThÃªm**:
```python
from src.services.postgres_database_service import PostgresDatabaseService
from src.services.hybrid_retrieval_service import HybridRetrievalService
from src.services.ingestion_service import IngestionService
```

**XÃ³a hoáº·c Comment**:
```python
# from src.services.database_service import DatabaseService  # OLD
# from src.services.faiss_service import FAISSService  # OLD
```

### 2. Initialization (__init__)
**Thay Ä‘á»•i**:
```python
# OLD
self.db_service = DatabaseService()
self.faiss_service = FAISSService()

# NEW
self.db_service = PostgresDatabaseService()
self.hybrid_retrieval = HybridRetrievalService(
    self.db_service, 
    self.embedding_service
)
self.ingestion_service = IngestionService(
    self.db_service,
    self.embedding_service,
    self.pdf_processor,
    self.hybrid_retrieval
)
```

### 3. Retrieval Method
**Thay Ä‘á»•i `retrieve_relevant_chunks()` method**:

```python
# OLD
def retrieve_relevant_chunks(self, query: str, top_k: int = 5):
    # Generate embedding
    query_embedding = self.embedding_service.generate_embedding(query)
    
    # Search FAISS
    faiss_results = self.faiss_service.search(query_embedding, top_k)
    
    # Get chunks from database
    chunks = [self.db_service.get_chunk_by_id(chunk_id) for chunk_id, _ in faiss_results]
    
    return chunks

# NEW
def retrieve_relevant_chunks(self, query: str, top_k: int = 5):
    # Generate embedding
    query_embedding = self.embedding_service.generate_embedding(query)
    
    # Hybrid search (dense + sparse)
    results = self.hybrid_retrieval.hybrid_search(
        query=query,
        query_embedding=query_embedding,
        top_k=top_k
    )
    
    return results
```

### 4. Initialization on Startup
**ThÃªm**:
```python
# Initialize ingestion service
if AUTO_INGEST_ON_STARTUP:
    log.info("ğŸ”„ Running initial PDF ingestion...")
    asyncio.run(self.ingestion_service.process_directory())
    log.info("âœ… Initial ingestion completed")

# Start file watcher
self.ingestion_service.start_watching()
```

### 5. Shutdown Cleanup
**ThÃªm**:
```python
def shutdown(self):
    """Cleanup on shutdown"""
    # Stop file watcher
    if self.ingestion_service:
        self.ingestion_service.stop_watching()
    
    # Close database connection
    if self.db_service:
        self.db_service.close()
```

## ğŸ“ Detailed Changes

### Method: `generate_answer()`
**Thay Ä‘á»•i**:
- Sá»­ dá»¥ng `hybrid_retrieval.hybrid_search()` thay vÃ¬ FAISS search
- Káº¿t quáº£ sáº½ cÃ³ thÃªm `dense_score` vÃ  `sparse_score`
- Cáº­p nháº­t `sources` formatting

```python
# OLD
chunks = self.retrieve_relevant_chunks(query, top_k=5)
sources = [chunk['source_file'] for chunk in chunks]

# NEW
results = self.retrieve_relevant_chunks(query, top_k=5)
sources = [result['source'] for result in results]
context = "\n".join([result['content'] for result in results])
```

### Method: `rerank_results()`
**CÃ³ thá»ƒ xÃ³a hoáº·c Ä‘Æ¡n giáº£n hÃ³a**:
- Hybrid retrieval Ä‘Ã£ cÃ³ reranking built-in
- Náº¿u cáº§n thÃªm reranking, cÃ³ thá»ƒ sá»­ dá»¥ng CrossEncoder

```python
# CÃ³ thá»ƒ giá»¯ cho advanced reranking
def rerank_results(self, results, query):
    # Use CrossEncoder for additional reranking
    # Optional: chá»‰ dÃ¹ng náº¿u cáº§n precision cao
    pass
```

### Method: `save_conversation()`
**Cáº­p nháº­t**:
- LÆ°u vÃ o PostgreSQL conversations table thay vÃ¬ in-memory dict

```python
# OLD
self.conversations[conversation_id] = {
    'messages': [...],
    'timestamp': datetime.now()
}

# NEW
self.db_service.save_conversation(
    conversation_id=conversation_id,
    user_message=message,
    assistant_response=response,
    sources=sources,
    confidence=confidence
)
```

## ğŸ§ª Testing Checklist

Sau khi cáº­p nháº­t, cáº§n test:

- [ ] PostgreSQL connection hoáº¡t Ä‘á»™ng
- [ ] Chunks Ä‘Æ°á»£c lÆ°u vÃ o database
- [ ] Embeddings Ä‘Æ°á»£c táº¡o vÃ  lÆ°u
- [ ] Dense search hoáº¡t Ä‘á»™ng
- [ ] Sparse search hoáº¡t Ä‘á»™ng
- [ ] Hybrid search káº¿t há»£p cáº£ hai
- [ ] Conversation history Ä‘Æ°á»£c lÆ°u
- [ ] PDF ingestion tá»± Ä‘á»™ng hoáº¡t Ä‘á»™ng
- [ ] File watcher phÃ¡t hiá»‡n PDF má»›i
- [ ] API endpoints hoáº¡t Ä‘á»™ng Ä‘Ãºng

## ğŸ“Š Performance Considerations

### Dense Search (pgvector)
- Sá»­ dá»¥ng IVFFlat index cho tá»‘c Ä‘á»™
- CÃ³ thá»ƒ switch sang HNSW náº¿u cáº§n tá»‘t hÆ¡n
- Cosine similarity: `1 - (embedding <=> query_embedding)`

### Sparse Search (BM25)
- In-memory index, ráº¥t nhanh
- Rebuild khi cÃ³ chunks má»›i
- Tá»‘t cho keyword matching

### Hybrid Combination
- Configurable weights (default: 70% dense, 30% sparse)
- CÃ³ thá»ƒ tune dá»±a trÃªn use case
- CÃ¢n báº±ng semantic + keyword matching

## ğŸš€ Deployment Steps

1. **Backup dá»¯ liá»‡u cÅ©** (SQLite)
   ```bash
   cp data/embeddings/chatbot.db data/embeddings/chatbot.db.backup
   ```

2. **Cáº­p nháº­t RAG Service**
   - Edit `src/services/rag_service.py`
   - Thay Ä‘á»•i imports
   - Cáº­p nháº­t methods

3. **Test locally**
   ```bash
   powershell python test_postgres_connection.py
   powershell python -m pytest tests/
   ```

4. **Migrate dá»¯ liá»‡u** (náº¿u cáº§n)
   - Táº¡o script Ä‘á»ƒ migrate tá»« SQLite sang PostgreSQL
   - Hoáº·c re-ingest táº¥t cáº£ PDFs

5. **Deploy**
   - Restart backend
   - Monitor logs
   - Verify functionality

## ğŸ“š Reference

- `src/services/postgres_database_service.py` - Database operations
- `src/services/hybrid_retrieval_service.py` - Hybrid search
- `src/services/ingestion_service.py` - PDF ingestion
- `config/settings.py` - Configuration

## ğŸ†˜ Common Issues

### Issue: "No module named 'pgvector'"
**Solution**: 
```bash
pip install pgvector
```

### Issue: "PostgreSQL connection refused"
**Solution**:
```bash
docker-compose ps  # Check if running
docker-compose logs postgres  # Check logs
```

### Issue: "Hybrid search returns empty results"
**Solution**:
- Kiá»ƒm tra chunks Ä‘Ã£ Ä‘Æ°á»£c insert
- Kiá»ƒm tra embeddings Ä‘Ã£ Ä‘Æ°á»£c táº¡o
- Kiá»ƒm tra BM25 index Ä‘Ã£ Ä‘Æ°á»£c build

## âœ… Completion Checklist

- [ ] Imports updated
- [ ] Initialization updated
- [ ] Retrieval methods updated
- [ ] Conversation storage updated
- [ ] Ingestion service integrated
- [ ] Tests passing
- [ ] Documentation updated
- [ ] Ready for deployment

---

**Next Step**: BÆ°á»›c 8 - Test & Verify há»‡ thá»‘ng

