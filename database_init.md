# Database Initialization Guide - H∆∞·ªõng d·∫´n Kh·ªüi t·∫°o Database

## üìã T·ªïng quan

H∆∞·ªõng d·∫´n n√†y s·∫Ω ch·ªâ b·∫°n c√°ch kh·ªüi t·∫°o, reset v√† qu·∫£n l√Ω database cho h·ªá th·ªëng RAG chatbot v·ªõi enhanced chunking strategy.

## üóÇÔ∏è C·∫•u tr√∫c Database

### Database Schema
Database s·ª≠ d·ª•ng SQLite v·ªõi 2 b·∫£ng ch√≠nh:

#### 1. B·∫£ng `chunks` (L∆∞u tr·ªØ c√°c ƒëo·∫°n vƒÉn b·∫£n)
```sql
CREATE TABLE chunks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    content TEXT NOT NULL,                    -- N·ªôi dung chunk
    source_file TEXT NOT NULL,               -- File PDF ngu·ªìn
    page_number INTEGER,                     -- S·ªë trang (n·∫øu c√≥)
    chunk_index INTEGER NOT NULL,           -- Th·ª© t·ª± chunk trong document
    
    -- Enhanced metadata fields (m·ªõi)
    heading_text TEXT,                       -- Text c·ªßa heading
    heading_level INTEGER,                   -- C·∫•p ƒë·ªô heading (1, 2, 3...)
    heading_number TEXT,                     -- S·ªë heading (vd: "7.3.1")
    parent_heading TEXT,                     -- Heading cha (vd: "7.3" cho "7.3.1")
    is_sub_chunk BOOLEAN DEFAULT FALSE,     -- C√≥ ph·∫£i sub-chunk kh√¥ng
    sub_chunk_index INTEGER,                -- Th·ª© t·ª± trong sub-chunks
    total_sub_chunks INTEGER,               -- T·ªïng s·ªë sub-chunks
    chunk_type TEXT DEFAULT 'content',      -- Lo·∫°i chunk: intro/heading/content
    word_count INTEGER,                     -- S·ªë t·ª´
    char_count INTEGER,                     -- S·ªë k√Ω t·ª±
    
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 2. B·∫£ng `embeddings` (L∆∞u tr·ªØ vector embeddings)
```sql
CREATE TABLE embeddings (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    chunk_id INTEGER NOT NULL,              -- Li√™n k·∫øt v·ªõi chunks.id
    embedding BLOB NOT NULL,                -- Vector embedding (768 dimensions)
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (chunk_id) REFERENCES chunks (id)
);
```

### Files ƒë∆∞·ª£c t·∫°o
- **Database**: `data/embeddings/chatbot.db`
- **FAISS Index**: `data/embeddings/faiss_index.index`
- **FAISS Metadata**: `data/embeddings/faiss_index.metadata`
- **Chunks JSON**: `data/processed/heading_chunks.json`
- **Analysis**: `data/processed/chunk_analysis_production.json`

## üöÄ C√°ch kh·ªüi t·∫°o Database

### Ph∆∞∆°ng ph√°p 1: Kh·ªüi t·∫°o t·ª´ ƒë·∫ßu (Khuy·∫øn ngh·ªã)

```bash
# K√≠ch ho·∫°t conda environment
conda activate uni_bot

# Reset v√† rebuild ho√†n to√†n
python scripts/reset_and_rebuild.py
```

**Qu√° tr√¨nh th·ª±c hi·ªán:**
1. **Backup** d·ªØ li·ªáu hi·ªán t·∫°i (n·∫øu c√≥)
2. **X√≥a** database, FAISS index, chunks files c≈©
3. **T·∫°o** database m·ªõi v·ªõi enhanced schema
4. **X·ª≠ l√Ω** t·∫•t c·∫£ PDF files v·ªõi enhanced chunking
5. **T·∫°o** embeddings cho t·∫•t c·∫£ chunks
6. **X√¢y d·ª±ng** FAISS index m·ªõi
7. **Ph√¢n t√≠ch** v√† l∆∞u k·∫øt qu·∫£

### Ph∆∞∆°ng ph√°p 2: Reset ƒë∆°n gi·∫£n

```bash
# Ch·ªâ x√≥a database v√† FAISS index
python scripts/reset_database.py

# Sau ƒë√≥ rebuild
python scripts/process_pdfs_with_headings.py
```

### Ph∆∞∆°ng ph√°p 3: Migration t·ª´ schema c≈©

```bash
# N·∫øu ƒë√£ c√≥ database c≈©, migrate schema
python scripts/migrate_database_schema.py

# Sau ƒë√≥ deploy chunking m·ªõi
python scripts/deploy_new_chunking.py
```

## üîß Scripts v√† ch·ª©c nƒÉng

### 1. `reset_and_rebuild.py` - Reset v√† rebuild ho√†n to√†n
**Ch·ª©c nƒÉng:**
- Backup d·ªØ li·ªáu hi·ªán t·∫°i
- X√≥a to√†n b·ªô database, FAISS index, files
- T·∫°o l·∫°i t·ª´ ƒë·∫ßu v·ªõi enhanced chunking
- T·ª± ƒë·ªông ph√¢n t√≠ch k·∫øt qu·∫£

**Khi n√†o s·ª≠ d·ª•ng:**
- L·∫ßn ƒë·∫ßu setup
- Mu·ªën l√†m s·∫°ch ho√†n to√†n
- Thay ƒë·ªïi chunking strategy
- C√≥ v·∫•n ƒë·ªÅ v·ªõi d·ªØ li·ªáu

### 2. `migrate_database_schema.py` - Migration schema
**Ch·ª©c nƒÉng:**
- Th√™m c√°c c·ªôt metadata m·ªõi v√†o b·∫£ng chunks
- C·∫≠p nh·∫≠t metadata cho chunks hi·ªán c√≥
- Backup tr∆∞·ªõc khi migration

**Khi n√†o s·ª≠ d·ª•ng:**
- ƒê√£ c√≥ database c≈©
- Mu·ªën gi·ªØ l·∫°i d·ªØ li·ªáu hi·ªán c√≥
- Upgrade schema

### 3. `deploy_new_chunking.py` - Deploy chunking m·ªõi
**Ch·ª©c nƒÉng:**
- Backup d·ªØ li·ªáu
- X√≥a chunks v√† embeddings c≈©
- X·ª≠ l√Ω l·∫°i PDFs v·ªõi enhanced chunking
- T·∫°o embeddings v√† FAISS index m·ªõi

**Khi n√†o s·ª≠ d·ª•ng:**
- Sau khi migrate schema
- Mu·ªën √°p d·ª•ng chunking m·ªõi
- Database schema ƒë√£ s·∫µn s√†ng

### 4. `analyze_chunks.py` - Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng
**Ch·ª©c nƒÉng:**
- Ph√¢n t√≠ch k√≠ch th∆∞·ªõc chunks
- Th·ªëng k√™ ph√¢n b·ªë
- ƒê∆∞a ra khuy·∫øn ngh·ªã
- T√¨m chunks c√≥ v·∫•n ƒë·ªÅ

**Khi n√†o s·ª≠ d·ª•ng:**
- Sau khi t·∫°o chunks
- Ki·ªÉm tra ch·∫•t l∆∞·ª£ng
- T·ªëi ∆∞u h√≥a parameters

### 5. `test_new_chunking.py` - Test chunking strategy
**Ch·ª©c nƒÉng:**
- Test chunking m·ªõi tr√™n PDFs
- So s√°nh v·ªõi chunking c≈©
- L∆∞u k·∫øt qu·∫£ test
- ƒê√°nh gi√° hi·ªáu su·∫•t

**Khi n√†o s·ª≠ d·ª•ng:**
- Tr∆∞·ªõc khi deploy
- Test thay ƒë·ªïi parameters
- So s√°nh strategies

## üìä Enhanced Chunking Strategy

### Nguy√™n t·∫Øc chunking m·ªõi:
1. **B·∫£o to√†n ho√†n to√†n n·ªôi dung** - Kh√¥ng b·ªè s√≥t b·∫•t k·ª≥ th√¥ng tin n√†o
2. **Chia theo heading hierarchy** - T√¥n tr·ªçng c·∫•u tr√∫c t√†i li·ªáu
3. **Merge chunks nh·ªè th√¥ng minh** - Tr√°nh m·∫•t ng·ªØ c·∫£nh
4. **Metadata phong ph√∫** - H·ªó tr·ª£ retrieval ch√≠nh x√°c

### Parameters t·ªëi ∆∞u:
- `min_chunk_size`: 100 characters
- `max_chunk_size`: 2500 characters  
- `target_chunk_size`: 1000 characters

### Lo·∫°i chunks:
- **intro**: Ph·∫ßn gi·ªõi thi·ªáu tr∆∞·ªõc heading ƒë·∫ßu ti√™n
- **heading**: Chunks ch·ª©a heading v√† n·ªôi dung
- **content**: Chunks n·ªôi dung th√¥ng th∆∞·ªùng

## üîç Ki·ªÉm tra v√† x√°c minh

### Ki·ªÉm tra database
```bash
# Xem th√¥ng tin chunks
python -c "
from src.services.database_service import DatabaseService
db = DatabaseService()
print(f'Total chunks: {db.get_chunk_count()}')
"

# Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng
python scripts/analyze_chunks.py
```

### Ki·ªÉm tra FAISS index
```bash
# Test FAISS index
python -c "
from src.services.faiss_service import FAISSService
faiss = FAISSService()
if faiss.load_index():
    print(f'FAISS index loaded: {faiss.index.ntotal} vectors')
else:
    print('Failed to load FAISS index')
"
```

### Ki·ªÉm tra files
```bash
# Ki·ªÉm tra files ƒë∆∞·ª£c t·∫°o
ls -la data/embeddings/
ls -la data/processed/
```

## üö® X·ª≠ l√Ω s·ª± c·ªë

### L·ªói "table chunks has no column named heading_text"
**Nguy√™n nh√¢n:** Database schema c≈© ch∆∞a c√≥ metadata columns
**Gi·∫£i ph√°p:**
```bash
python scripts/migrate_database_schema.py
```

### L·ªói "No PDF files found"
**Nguy√™n nh√¢n:** Kh√¥ng c√≥ file PDF trong th∆∞ m·ª•c `data/pdfs/`
**Gi·∫£i ph√°p:**
- Copy file PDF v√†o `data/pdfs/`
- Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n trong `config/settings.py`

### L·ªói "Failed to load FAISS index"
**Nguy√™n nh√¢n:** FAISS index b·ªã l·ªói ho·∫∑c ch∆∞a t·∫°o
**Gi·∫£i ph√°p:**
```bash
python scripts/reset_and_rebuild.py
```

### L·ªói embedding model
**Nguy√™n nh√¢n:** Model ch∆∞a download ho·∫∑c l·ªói m·∫°ng
**Gi·∫£i ph√°p:**
- Ki·ªÉm tra k·∫øt n·ªëi internet
- Th·ª≠ l·∫°i sau v√†i ph√∫t
- Thay ƒë·ªïi model trong `config/settings.py`

## üìÅ Backup v√† Recovery

### T·ª± ƒë·ªông backup
T·∫•t c·∫£ scripts ƒë·ªÅu t·ª± ƒë·ªông t·∫°o backup tr∆∞·ªõc khi thay ƒë·ªïi:
- `data/processed/backup/database_backup_YYYYMMDD_HHMMSS.db`
- `data/processed/backup/chunks_backup_YYYYMMDD_HHMMSS.json`
- `data/embeddings/backup/database_pre_migration_YYYYMMDD_HHMMSS.db`

### Kh√¥i ph·ª•c t·ª´ backup
```bash
# Kh√¥i ph·ª•c database
cp data/processed/backup/database_backup_YYYYMMDD_HHMMSS.db data/embeddings/chatbot.db

# Kh√¥i ph·ª•c chunks
cp data/processed/backup/chunks_backup_YYYYMMDD_HHMMSS.json data/processed/heading_chunks.json
```

## üéØ Best Practices

### 1. Lu√¥n backup tr∆∞·ªõc khi thay ƒë·ªïi
```bash
# T·∫°o backup th·ªß c√¥ng
cp data/embeddings/chatbot.db data/embeddings/chatbot_backup_$(date +%Y%m%d_%H%M%S).db
```

### 2. Ki·ªÉm tra k·∫øt qu·∫£ sau m·ªói l·∫ßn rebuild
```bash
python scripts/analyze_chunks.py
```

### 3. Test tr∆∞·ªõc khi deploy production
```bash
python scripts/test_new_chunking.py
```

### 4. Monitor ch·∫•t l∆∞·ª£ng chunks
- Ki·ªÉm tra t·ª∑ l·ªá chunks trong kho·∫£ng t·ªëi ∆∞u (500-3000 chars)
- ƒê·∫£m b·∫£o √≠t chunks qu√° nh·ªè (<100 chars) ho·∫∑c qu√° l·ªõn (>3000 chars)
- Xem x√©t metadata completeness

### 5. C·∫≠p nh·∫≠t khi c√≥ PDF m·ªõi
```bash
# Th√™m PDF m·ªõi v√†o data/pdfs/ r·ªìi ch·∫°y
python scripts/reset_and_rebuild.py
```

## üìû H·ªó tr·ª£

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ:
1. Ki·ªÉm tra logs trong `logs/chatbot.log`
2. Ch·∫°y `python scripts/analyze_chunks.py` ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu
3. Th·ª≠ reset ho√†n to√†n: `python scripts/reset_and_rebuild.py`
4. Ki·ªÉm tra conda environment: `conda activate uni_bot`
